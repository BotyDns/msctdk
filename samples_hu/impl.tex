\chapter{Megvalósítás és alkalmazás}
\label{ch:impl}

\section{A meglevő alkalmazások bővítése}
\label{ch:application-improvement}

\subsection {Az asztali alkalmazás bővítése}

A meglevő asztali alkalmazás alkalmas volt a tanítóadatok hatékony előállítására, de utólag nem lehetett visszanézni, hogy adott műholdfelvételhez milyen tanítóadatok tartoznak, illetve azt sem, hogy az adott tanítóadat hol volt mintavételezve. Az alkalmazás eredetileg egy CSV fájlban \cite{rfc4180} tárolta el az összes pixel spektrális értékeit és indexeit, és ezt lehetett használni tanításra. Ennek az volt a hátránya, hogy nehéz volt áttekinteni illetve kiegészíteni az adatokat. Ezért az asztali alkalmazást kiegészítettem ezzel a funkcionalitással, a tanítóadatok előállítása elmentésekor az alkalmazás létrehoz egy külön raszteres réteget is külön minden műholdfelvételhez, melyen látható, hogy mely területek voltak hozzáadva a tanítóadatok közé, így tetszőleges módon előállítható/ellenőrizhető a tanítóhalmaz.

\subsection {A szerveralkalmazás bővítése}

A szerveralkalmazás és webalkalmazás is bővítésre került: a szerveralkalmazás mostmár több modellt is le tud futtatni a letöltött műholdfelvételeken és ezeket külön tárolja. A webalkalmazás mostmár képes letölteni külön ezeket az eredményeket és több hulladékmaszkoló módszer eredményét is meg tudja jeleníteni, ennek köszönhetően ezeket egymással össze lehet könnyen hasonlítani valós tesztadatokon \todo{Melyik linket írjam ide, mit írjak szerzőnek?}. A \ref{fig:waste-detection-demo} ábrán látható, ahogy lehet váltakozni a hulladékdetektálási modellek között, és a \ref{tab:model-ids} táblázat szerint lehet beazonosítani a dolgozatban említett modelleket. Az "old\_model"\todo[color=blue!50]{Tipográfiai kiemelés jobb, pl. \texttt{old\_model}}-en kívül az összes model a \ref{ch:training} fejezetben részletezett súlyozással és méretcsökkentési módszerekkel tanítottam be.
\todo[inline,color=blue!50]{Forráskód szintjén a kari GitLab-os repóban van egy public branch, ami tükrözésre kerül GitHub-ra, ide: https://github.com/GISLab-ELTE/WasteDetection\\
A dolgozatban a GitHub-os repó szerepeljen, mert az érhető el publikusan csak.\\
Ha magát a webalkamazás demó felületét akarod hivatkozni, akkor a https://gis.inf.elte.hu/waste-detection/ link adható meg.}

\begin{figure}[H]
	\centering
	\subcaptionbox{A webalkalmazás a régi modell eredményeit mutatja a Drinán}{
		\includegraphics[width=0.45\linewidth]{webapp-drina-old}}
	\hspace{5pt}
	\subcaptionbox{A webalkalmazás az új modell eredményeit mutatja a Drinán}{
		\includegraphics[width=0.45\linewidth]{webapp-drina-new}}
	\caption{A webalkalmazás képes több modellnek az eredményét is összehasonlítóképpen megmutatni}
	\label{fig:waste-detection-demo}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{ | p{0.3\textwidth} | p{0.7\textwidth} | }
		\hline
		\textbf{Modell azonosító} & \textbf{Modell leírás} \\
		\hline \hline
		\emph{old\_model} & A Régi modell, ami \cite{magyar2023}-ban lett betanítva \\
		\hline
		\emph{allweather\_model} & Egy olyan modell, ami kizárólag a romániai hulladéklerakókon volt betanítva. \\
		\hline
		\emph{summer\_model} & A nyári intervallumban található adatokon tanított modell.  \\
		\hline
        \emph{winter\_model} & A téli intervallumban található adatokon tanított modell. \\
        \hline
        \emph{kiskore\_model} & A romániai hulladéklerakókon és a kiskörei víztorlaszon tanított modell. \\
		\hline
        \emph{with\_extra\_unknown\_model} & Amikor a dolgozatomban az "új modell"-re hivatkozok, erre gondolok. hasonlóan volt betanítva, mint a kiskore\_model, annyi különbséggel, hogy hozzávettem több "Ismeretlen" címkéhez tartozó adatot, azért, hogy csökkentsem az utak miatt okozott false-positive-okat. \\
		\hline
	\end{tabular}
	\caption{A külön nyári és téli időszakra tanított modellek átlagai}
	\label{tab:model-ids}
\end{table}

\section{A Tiszta-Tisza alkalmazás}

A Tiszta-Tisza webalkalmazás \todo{melyik link kerüljön ide?} a PET Kupa által használt webalkalmazás, melynek az a célja, hogy egy olyan felületet biztosítson, ahol meglehet tekinteni a jelenleg ismert folyómentén található hulladéklerakókat, illetve akár a regisztrált felhasználók is be tudnak jelenteni ilyet. A PET Kupa megbízta az egyetemet azzal a feladattal, hogy ezt továbfejlessze, és a feladatok közé tartozott az is, hogy a Random Forest modell eredményeit integráljuk ebbe az alkalmazásba. Ezt a feladatot én vállaltam el.

Tekintve arra, hogy a Tiszta-Tisza térképén pontok vannak megjelenítve, a modell által detektált területeket is pontokkal jelöljük. Ehhez egy nagyobb terület közepére helyezünk el egy pontot. Előfordulhat olyan is, hogy a modell olyan képeket klasszifikál, melyek el vannak torzítva (például magas páratartalom miatt). Ilyenkor a false-positive-ok aránya lényegesen megnő. Ennek korrigálására a Tiszta-Tisza alkalmazásban a legutolsó három detektálást (legfeljebb 1 hónap különbséggel) veszem figyelembe és két kép közös metszetével döntöm el, hogy milyen területek kerülnek fel a térképre. A \ref{fig:clean-tisza} ábrán láthatóak a hulladékdetektálás során előállított pontok a térképen, melyeket egy nagyítóval vannak jelölve, melyben van egy felkiáltójel. A Hulladékdetektálás konverzióját a térképen látható pontokká a \ref{ch:intersection} fejezetben részletezem.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth,frame]{clean-tisza}
	\caption{A hulladékdetektálás által megjelenített pontok a térképen.}
    \label{fig:clean-tisza}
\end{figure}

\subsection{A képfeldolgozás gyorsítása}
A meglevő képfeldolgozó algoritmuson gyorsítani kellett, hogy elfogadható időn belül tudja feldolgozni a tanítóadatokat, illetve a naponta letöltött műholdfelvételeket a szerveren. Ezt a kutatólabor korábbi cikkjében párhuzamosítással javasolták, de egy egyszálú megoldással lényegesen tudtam gyorsítani a képfeldolgozáson: Ehhez egy nagyon hatékony Python programcsomagot, a Numpy-t \cite{harris2020array} használtam fel, mellyel lényegesen megnöveltem a feldolgozás sebességét: A tanítóadatok feldolgozásakor a régi módszer (\ref{src:old-code} forráskód) 16 felvételt tudott feldolgozni 4 nap és 10 óra alatt, míg az átírt módszer (\ref{src:new-code} forráskód) feldolgozott 85 felvételt 20 perc alatt.

\lstset{caption={A képfeldolgozás régi módszere}, label=src:old-code}
\begin{lstlisting}[language={Python}]
def _calculate_index(numerator: np.ndarray, denominator: np.ndarray) -> np.ndarray:
    """
    Calculating an index based on given numerator and denominator.

    :param numerator: numerator matrix
    :param denominator: denominator matrix
    :return: result matrix, containing the calculated values
    """

    # variables
    rows = numerator.shape[0]
    cols = numerator.shape[1]
    index = np.ndarray(
        shape=numerator.shape,
        dtype="float32",
    )

    # calculate index
    for i in range(rows):
        for j in range(cols):
            if np.isnan(numerator[i, j]) or np.isnan(denominator[i, j]):
                index[i, j] = float("NaN")
            elif denominator[i, j] != 0:
                index[i, j] = numerator[i, j] / denominator[i, j]
            else:
                if numerator[i, j] < 0:
                    index[i, j] = np.nanmin(numerator)
                elif numerator[i, j] > 0:
                    index[i, j] = np.nanmax(numerator)
                else:
                    index[i, j] = float("NaN")

    # return index values
    return index
\end{lstlisting}

\lstset{caption={A képfeldolgozás numpy-al}, label=src:new-code}

\begin{lstlisting}[language={Python}]
def calculate_index(numerator: np.ndarray, denominator: np.ndarray) -> np.ndarray:
    """
    Calculating an index based on given numerator and denominator.
    
    :param numerator: numerator matrix
    :param denominator: denominator matrix
    :return: result matrix, containing the calculated values
    """
    
    # variables
    index = np.ndarray(
        shape=numerator.shape,
        dtype="float32",
    )
    
    numerator_nan_min = np.nanmin(numerator)
    numerator_nan_max = np.nanmax(numerator)
    
    # calculate index
    nan_mask = np.isnan(numerator) | np.isnan(denominator)
    numerator_zero_mask = numerator == 0
    denominator_zero_mask = denominator == 0
    
    invalid_mask = nan_mask | (numerator_zero_mask & denominator_zero_mask)
    valid_mask = np.logical_not(invalid_mask)
    
    valid_denominator_non_zero_mask = valid_mask & np.logical_not(denominator_zero_mask)
    valid_denominator_zero_mask = valid_mask & denominator_zero_mask
    
    numerator_positive_denominator_zero_mask = valid_denominator_zero_mask & (numerator > 0)
    numerator_negative_denominator_zero_mask = valid_denominator_zero_mask & (numerator < 0)
    
    index[invalid_mask] = float("NaN")
    index[numerator_positive_denominator_zero_mask] = numerator_nan_max
    index[numerator_negative_denominator_zero_mask] = numerator_nan_min
    index[valid_denominator_non_zero_mask] = (
        numerator[valid_denominator_non_zero_mask] / denominator[valid_denominator_non_zero_mask]
    )
    
    # return index values
    return index
\end{lstlisting}

\cite{magyar2023}-ban megmérték a modell feldolgozási sebességét különböző méretű felvételeken. Az első felvételt el tudtam kérni a szerzőtől, de a többi felvételt újból előállítottam, igyekezve arra, hogy hasonló legyen a felvételek mérete. A \ref{tab:old-speed} táblázatban találhatóak a régi feldolgozás sebességei a régi modell mellett. A \ref{tab:new-speed} táblázatban látható a régi és új modell feldolgozási sebessége az új számolási módszerrel \todo{új módszert is megjeleníteni}. Fontos megjegyezni azt, hogy nem ugyanazon a számítógépen történt az új módszer sebességének a lemérése, de a két számítógép számolóképessége ugyanabban a súlycsoportban van. A két táblázatból láthatjuk, hogy az új indexszámolási módszer körülbelül felére csökkentette a feldolgozási és osztályozási időt, mostmár az idő nagy része az osztályozással és az osztályozás feldolgozásával megy el. További kutatás esetén érdemes lehet megvizsgálni az osztályozás feldolgozásával kapcsolatos lassulásokat annak érdekében, hogy ezt a feldolgozást is gyorsítsuk.

\begin{table}[H]
	\centering
	\begin{tabular}{ | p{0.45\textwidth} | p{0.45\textwidth} | }
		\hline
		\textbf{Felvétel mérete (pixel)} & \textbf{feldolgozási idő} \\
		\hline \hline
		164 × 312 = 51 168  & 2.17 mp  \\
		\hline
		1194 × 801 = 956 394 & 39.98 mp\\
		\hline
		4597 × 4153 = 19 091 341 & 12 perc 42 mp \\
		\hline
        6614 × 5981 = 39 558 334 & 26 perc 5 mp  \\
		\hline
	\end{tabular}
	\caption{A régi modell régi módszerrel való feldolgozási ideje}
	\label{tab:old-speed}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{ | p{0.45\textwidth} | p{0.45\textwidth} | }
		\hline
		\textbf{Felvétel mérete (pixel)} & \textbf{Feldolgozási idő (Régi modell)} \\
		\hline \hline
		164 × 312 = 51 168  & 1.88mp  \\
		\hline
		1262 × 820 = 1 034 840 & 19.06 mp\\
		\hline
		4951 × 4002 = 19 813 902 & 6 perc 16 mp \\
		\hline
        10366 × 3860 = 40 012 760 & 14 perc 24 mp  \\
		\hline
	\end{tabular}
	\caption{A régi és új modell új módszerrel való feldolgozási ideje}
	\label{tab:new-speed}
\end{table}

\section{Közös metszet}
\label{ch:intersection}

A már meglevő szervertől poligonok formájában, GeoJSON-ben \cite{rfc7946} lehet lekérni az adott napon detektált hulladékos területeket. így érdemes poligonok metszetében kigondolni a többségi szavazást. Jelöljük BUF(P,n)-vel egy multipoligon pufferét, ahol $P \in \mathbb{P}$ egy multipoligon, és n egy egész szám. Ekkor a többségi szavazást három képre a \ref{eq:voting} \todo{hasonló képleteket mások is ismernek fórumokban, de hivatalos forrással nem találkoztam\\Máté: ha nem csak komment szintjén jelenik meg, hanem pl. egy blog poszt, az hivatkozható} képlet szerint lehet alkalmazni. Ezután a poligonok egy-egy belső pontját megválasztva megtudjuk jelölni a hulladéklerakókat. A megközelítés szavakra bontva a következő: az összes multipoligon párra vesszük a két multipoligon metszetét, (ahol egy n méretű hibahatár is belefér a metszet számolásba), utána a poligonpárokat rendre összeúniózzuk. A \ref{fig:union-intersection} ábra vizualizálja a képlet lépéseit. Ezzel a módszerrel ki lehet szűrni azokat a hibákat, melyek rossz minőségű felvételek miatt keletkeznek. Tekintve arra, hogy nem minden Planet felvétel kerül osztályozásra, mivel előfordulnak hiányos vagy felhős felvételek, érdemes megszabni egy időintervallumot, amin belül alkalmazható a többségi szavazás. A dolgozat írásának idejében legfeljebb 1 hónap intervallumon el kell helyezkedjen mind a három felvétel.

\begin{equation}\label{eq:voting}
    Eredm\acute{e}ny \ multipoligon = \bigcup_{P_1 \in \mathbb{P}} \bigcup_{P_2 \in \mathbb{P}} BUF(BUF(P_1,n) \cap BUF(P_2,n),-n)
\end{equation}

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth,frame]{Waste_markings_flow}
	\caption{A \ref{eq:voting} képlet lépései}
    \label{fig:union-intersection}
\end{figure}