@book{dahl1972structured,
	editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
	title = {Structured Programming},
	year = {1972},
	isbn = {0-12-200550-3},
	source = {Library of Congress Catalog Card Number: 72-84452},
	publisher = {Academic Press Ltd.},
	address = {London, UK, UK},
}

@book{cormen2009algorithms,
	author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
	title = {Introduction to Algorithms, Third Edition},
	year = {2009},
	isbn = {0262033844, 9780262033848},
	edition = {3rd},
	publisher = {The MIT Press},
}

@incollection{dijkstra1979goto,
	author = {Dijkstra, E.},
	chapter = {Go to Statement Considered Harmful},
	title = {Classics in Software Engineering},
	editor = {Yourdon, Edward Nash},
	year = {1979},
	isbn = {0-917072-14-6},
	pages = {27--33},
	numpages = {7},
	url = {http://dl.acm.org/citation.cfm?id=1241515.1241518},
	acmid = {1241518},
	publisher = {Yourdon Press},
	address = {Upper Saddle River, NJ, USA},
}

@article{krasner1988mvc,
	author = {Krasner, Glenn E. and Pope, Stephen T.},
	title = {A Cookbook for Using the Model-View-Controller User Interface Paradigm in Smalltalk-80},
	journal = {J. Object Oriented Program.},
	issue_date = {Aug./Sept. 1988},
	volume = {1},
	number = {3},
	month = aug,
	year = {1988},
	issn = {0896-8438},
	pages = {26--49},
	numpages = {24},
	url = {http://dl.acm.org/citation.cfm?id=50757.50759},
	acmid = {50759},
	publisher = {SIGS Publications},
	address = {Denville, NJ, USA},
} 

@article{kibria2023PlasticWaste,
	author = { Kibria, M.G. and Masuk, N.I. and Safayet, R. et al. },
	title = { Plastic Waste: Challenges and Opportunities to Mitigate Pollution and Effective Management },
	journal = { International Journal of Environmental Research },
	issue_date = {Jan. 2023},
	volume = {17},
	number = {20},
	month = jan,
	year = {2023},
	issn = {2008-2034},
	url = {https://doi.org/10.1007/s41742-023-00507-z},
}

@inproceedings{magyar2023,
	author = {Magyar, Dávid and Cserép, Máté and Vincellér, Zoltán and Molnár, Attila},
	year = {2023},
	month = {01},
	title = {Waste Detection and Change Analysis based on Multispectral Satellite Imagery},
	doi = {10.48550/arXiv.2303.14521}
}

@website{wasteromania2019,
	author = {InfoCons.ro},
	urldate = {2024-04-02},
	url = {https://fiiunexemplu.ro/in-romania-exista-46-depozite-de-deseuri-gropi-de-gunoi/},
}

@website{planetsensors2024,
	author = {Planet.com},
	urldate = {2024-04-03},
	url = {https://developers.planet.com/docs/apis/data/sensors/},
}

@website{planetresolution2024,
	author = {Planet.com},
	urldate = {2024-04-03},
	url = {https://developers.planet.com/docs/apis/data/sensors/},
}

@misc{rfc7946,
    series =    {Request for Comments},
    number =    7946,
    howpublished =  {RFC 7946},
    publisher = {RFC Editor},
    doi =       {10.17487/RFC7946},
    url =       {https://www.rfc-editor.org/info/rfc7946},
    author =    {H. Butler and M. Daly and A. Doyle and Sean Gillies and T. Schaub and Stefan Hagen},
    title =     {{The GeoJSON Format}},
    pagetotal = 28,
    year =      2016,
    month =     aug,
    abstract =  {GeoJSON is a geospatial data interchange format based on JavaScript Object Notation (JSON). It defines several types of JSON objects and the manner in which they are combined to represent data about geographic features, their properties, and their spatial extents. GeoJSON uses a geographic coordinate reference system, World Geodetic System 1984, and units of decimal degrees.},
}

@article{CONGALTON199135,
title = {A review of assessing the accuracy of classifications of remotely sensed data},
journal = {Remote Sensing of Environment},
volume = {37},
number = {1},
pages = {35-46},
year = {1991},
issn = {0034-4257},
doi = {https://doi.org/10.1016/0034-4257(91)90048-B},
url = {https://www.sciencedirect.com/science/article/pii/003442579190048B},
author = {Russell G. Congalton},
abstract = {This paper reviews the necessary considerations and available techniques for assessing the accuracy of remotely sensed data. Included in this review are the classification system, the sampling scheme, the sample size, spatial autocorrelation, and the assessment techniques. All analysis is based on the use of an error matrix or contingency table. Example matrices and results of the analysis are presented. Future trends including the need for assessment of other spatial data are also discussed.}
}

@article{pca2010,
author = {Abdi, Hervé and Williams, Lynne J.},
title = {Principal component analysis},
journal = {WIREs Computational Statistics},
volume = {2},
number = {4},
pages = {433-459},
keywords = {singular and eigen value decomposition, bilinear decomposition, factor scores and loadings, RESS PRESS, multiple factor analysis},
doi = {https://doi.org/10.1002/wics.101},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.101},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wics.101},
abstract = {Abstract Principal component analysis (PCA) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the PCA model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. PCA can be generalized as correspondence analysis (CA) in order to handle qualitative variables and as multiple factor analysis (MFA) in order to handle heterogeneous sets of variables. Mathematically, PCA depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (SVD) of rectangular matrices. Copyright © 2010 John Wiley \& Sons, Inc. This article is categorized under: Statistical and Graphical Methods of Data Analysis > Multivariate Analysis Statistical and Graphical Methods of Data Analysis > Dimension Reduction},
year = {2010}
}

@Article{breiman2001,
author={Breiman, Leo},
title={Random Forests},
journal={Machine Learning},
year={2001},
month={Oct},
day={01},
volume={45},
number={1},
pages={5-32},
abstract={Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
issn={1573-0565},
doi={10.1023/A:1010933404324},
url={https://doi.org/10.1023/A:1010933404324}
}
